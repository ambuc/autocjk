# AutoCJK

AutoCJK is a tool for generating low-resolution predictions of uncommon CJK
characters, given full-width images of their components.

Example:

![U+20E74](docs/images/0x134772.png)

(Left-to-right: (a) source left-hand component, (b) source right-hand component,
(c) expected composition, (d) predicted composition, (e) c/d difference)

## Quickstart

### How do I generate a new character?

For example, given a font at `~/Downloads/font.otf`, we can render `⿰市來` and
write the generated image to `/tmp/out.png` with:

```
bazel run //src:main -- \
  --font_path=<path_to_font> \
  --lhs='市' \
  --rhs='來' \
  --out=/tmp/out.png
```

## Usage guide:

Bundled with this repo is `/src/generator.h5`, a trained model with pretty good
results. This generator was trained on ~270k image pairs, generated by
extracting characters from the fonts `NotoSansCJKsc-*` and `NotoSerifCJKsc-*`.

The resultant generator is pretty good at generating characters in that style.
It might even be pretty good at generating characters in a new style. If you
discover it's not, you can (a) generate a new batch of training images in your
own font style, and (b) run `model.py` in order to train a new model. If you
save that model as `src/generator.h5`, you can continue to use `bazel run //src:main` as expected.

## Development:

1. Run tests, autoformatting, etc. before submitting.

   ```bash
   bazel test ...
   # pip install yapf
   yapf -i src/**.py
   # pip install mdformat
   find . -iname 'README.md' | xargs mdformat
   ```

## TODO

1. Write evaluator scripts.

   It should be pretty simple to compare a `generator.h5` against existing
   fonts for an out-of-sample pixel-difference evaluation.

1. Support a wider range of IDS sequences.

   At the moment this generator can only render characters with an IDS like
   "⿰XY". We should support "⿱XY", "⿲XYZ", "⿳XYZ", etc, etc. These will
   be trickier.

1. Support region-aware generation.

   Most of the training and testing was performed in cn-zh. But the underlying
   utilities and fonts certainly support a wider range of regions.

1. Enable python typed libraries / binaries.

   This is probably quite simple in Bazel, but we haven't done it yet.

1. Experiment with other loss models.

   We might get images with crisper edges if our model uses a different loss
   function.

1. Experiment with generating smaller images.

   If running generator.py proves slow, we should generate smaller images.
